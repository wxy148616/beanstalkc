beanstalkc Tutorial
===================

> Welcome, dear stranger, to a tour de force through beanstalkd's capabilities.
Say hello to your fellow travel companion, the beanstalkc client library for
Python. You'll get to know each other fairly well during this trip, so better
start off on a friendly note. And now, let's go!


> Getting Started

开始
---------------

> You'll need beanstalkd listening at port 14711 to follow along. So simply start
it using: `beanstalkd -l 127.0.0.1 -p 14711`

beanstalkd监听14711端口，开启beanstalkd `beanstalkd -l 127.0.0.1 -p 14711`

> Besides having beanstalkc installed, you'll typically also need PyYAML. If you
insist, you can also use beanstalkc without PyYAML. For more details see
Appendix A of this tutorial.

安装beanstalkc，通常需要安装PyYAML。 如果你坚持不装，那就不装吧，你也可以使用beanstalkc即使不装PyYAML。更多详细请看教程最后的附录A。

> To use beanstalkc we have to import the library and set up a connection to an
(already running) beanstalkd server:

使用beanstalkc，必须先import这个库，并建立一条连接到正在运行的beanstalkd server:

    >>> import beanstalkc
    >>> beanstalk = beanstalkc.Connection(host='localhost', port=14711)

> If we leave out the `host` and/or `port` parameters, `'localhost'` and `11300`
would be used as defaults, respectively. There is also a `connect_timeout`
parameter which determines how long, in seconds, the socket will wait for the
server to respond to its initial connection attempt. If it is `None`, then
there will be no timeout; it defaults to the result of your system's
`socket.getdefaulttimeout()`.

如果遗漏了`host` 和／或 `port`参数，分别默认使用`'localhost'`和 `11300`。参数`connect_timeout`是socket等待server返回初始化连接的秒数，
如果是`None`, 将会没有时间限制；默认是你系统的`socket.getdefaulttimeout()`。


> Basic Operation

基础操作
---------------

> Now that we have a connection set up, we can enqueue jobs:

现在我们建立了一条连接，我们可以入队jobs:

    >>> beanstalk.put('hey!')
    1

> Or we can request jobs:

或者，我们可以请求jobs:

    >>> job = beanstalk.reserve()
    >>> job.body
    'hey!'

> Once we are done with processing a job, we have to mark it as done, otherwise
jobs are re-queued by beanstalkd after a "time to run" (120 seconds, per
default) is surpassed. A job is marked as done, by calling `delete`:

一旦我们处理完成一个job, 我们必须将它标记成已完成，否则jobs会在一个"time to run"(默认120s)之后重新进入队列。调用`delete`将job标记为已完成:

    >>> job.delete()

> `reserve` blocks until a job is ready, possibly forever. If that is not desired,
we can invoke `reserve` with a timeout (in seconds) how long we want to wait to
receive a job. If such a `reserve` times out, it will return `None`:

`reserve`会阻塞直到一个job是ready状态, 也许会永远阻塞在那。如果这不是所期望的，我们可以调用在`reserve`时加上一个等待接收job的超时秒数。
如果这样的`reserve`超时了，将返回`None`:

    >>> beanstalk.reserve(timeout=0) is None
    True

> If you use a timeout of 0, `reserve` will immediately return either a job or
`None`.

如果你把timeout设为0，`reserve`将会立即返回一个job或者None。

> Note that beanstalkc requires job bodies to be strings, conversion to/from
strings is left up to you:

注意, job的bodies是必须是字符串:

    >>> beanstalk.put(42)
    Traceback (most recent call last):
    ...
    AssertionError: Job body must be a str instance

> There is no restriction on what characters you can put in a job body, so they
can be used to hold arbitrary binary data:

没有限制放入job body中的是什么字符，因此可以支持任意二进制数据:

    >>> _ = beanstalk.put('\x00\x01\xfe\xff')
    >>> job = beanstalk.reserve() ; print(repr(job.body)) ; job.delete()
    '\x00\x01\xfe\xff'

> If you want to send images, just `put` the image data as a string. If you want
to send Unicode text, just use `unicode.encode` to convert it to a string with
some encoding.

如果你想发送图片，只要将图片转成字符串（比如base64）再`put`就行了。如果你想发送Unicode文本，调用`unicode.encode`加上编码转成string就可以了。

> Tube Management

Tube管理
---------------

> A single beanstalkd server can provide many different queues, called "tubes" in
beanstalkd. To see all available tubes:

单个beanstalkd server可以提供很多不同的队列，在beanstalkd中调用"tubes", 可以看到所有可用的tubes:

    >>> beanstalk.tubes()
    ['default']

> A beanstalkd client can choose one tube into which its job are put. This is the
tube "used" by the client. To see what tube you are currently using:

一个beanstalkd client可以选择job放入的tube，来看看你正在使用哪个tube：

    >>> beanstalk.using()
    'default'

> Unless told otherwise, a client uses the 'default' tube. If you want to use a
different tube:

除非明确告诉它，否则client使用`default`tube, 如果你想使用一个不同的tube:

    >>> beanstalk.use('foo')
    'foo'
    >>> beanstalk.using()
    'foo'

> If you decide to use a tube, that does not yet exist, the tube is automatically
created by beanstalkd:

如果你决心使用一个不存在的tube, beanstalkd会自动创建这个tube：

    >>> beanstalk.tubes()
    ['default', 'foo']

> Of course, you can always switch back to the default tube. Tubes that don't have
any client using or watching, vanish automatically:

当然，你随时可以切换回到默认的tube。 没有任何client using或者watching的管道会自动消失：

    >>> beanstalk.use('default')
    'default'
    >>> beanstalk.using()
    'default'
    >>> beanstalk.tubes()
    ['default']

> Further, a beanstalkd client can choose many tubes to reserve jobs from. These
tubes are "watched" by the client. To see what tubes you are currently watching:

更进一步，一个beanstalkd client可以选择从很多tubes来reserve jobs， 这些tubes被client "watched", 来看看你正在watching哪些tubes:

    >>> beanstalk.watching()
    ['default']

> To watch an additional tube:

watch额外的tube:

    >>> beanstalk.watch('bar')
    2
    >>> beanstalk.watching()
    ['default', 'bar']

> As before, tubes that do not yet exist are created automatically once you start
watching them:

像之前一样，一旦你watching一个不存在的tube, 这个tube会被自动创建：

    >>> beanstalk.tubes()
    ['default', 'bar']

> To stop watching a tube:

停止watching一个tube:

    >>> beanstalk.ignore('bar')
    1
    >>> beanstalk.watching()
    ['default']

> You can't watch zero tubes. So if you try to ignore the last tube you are
watching, this is silently ignored:

你不能watch 0个tube, 因此，如果你尝试ignore最后一个你在watching的tube, 这将会默默的被忽略掉:

    >>> beanstalk.ignore('default')
    0
    >>> beanstalk.watching()
    ['default']

> To recap: each beanstalkd client manages two separate concerns: which tube
newly created jobs are put into, and which tube(s) jobs are reserved from.
Accordingly, there are two separate sets of functions for these concerns:

  - `use` and `using` affect where jobs are `put`;
  - `watch` and `watching` control where jobs are `reserve`d from.
  
 
总结：每一个beanstalkd client管理着两个不同的关注点：最新创建的jobs放在了哪个tube中；jobs从哪个（些）tube中reserved。相应的，为了这两个关注点
有两个不同的函数集合：

  - `use` 和 `using` 影响着 job `put`到哪里
  - `watch` 和 `watching` 控制jobs从哪里`reserve`d

> Note that these concerns are fully orthogonal: for example, when you `use` a
tube, it is not automatically `watch`ed. Neither does `watch`ing a tube affect
the tube you are `using`.

注意：这些关注点是完全正交的：例如，当你`use`一个tube, 它不会自动被`watch`ed。当你使用`using`的时候也不会`watch`ing一个tube。

> Statistics

统计
----------

> Beanstalkd accumulates various statistics at the server, tube and job level.
Statistical details for a job can only be retrieved during the job's lifecycle.
So let's create another job:

Beanstalkd在server中积聚着各种tube和job级别的统计数据。job的统计细节只能在job的生命周期中取到。所以，来创建另一个job：

    >>> beanstalk.put('ho?')
    3

    >>> job = beanstalk.reserve()

> Now we retrieve job-level statistics:

现在，我们取到了job-level的统计数据：

    >>> from pprint import pprint
    >>> pprint(job.stats())                         # doctest: +ELLIPSIS
    {'age': 0,
     ...
     'id': 3,
     ...
     'state': 'reserved',
     ...
     'tube': 'default'}

> If you try to access job stats after the job was deleted, you'll get a
`CommandFailed` exception:

如果你在job被deleted之后，尝试获取job stats，你将会得到一个`CommandFailed`异常：

    >>> job.delete()
    >>> job.stats()                         # doctest: +IGNORE_EXCEPTION_DETAIL
    Traceback (most recent call last):
    CommandFailed: ('stats-job', 'NOT_FOUND', [])

> Let's have a look at some numbers for the `'default'` tube:

让我们来看看一些`default`tube的数据：

    >>> pprint(beanstalk.stats_tube('default'))     # doctest: +ELLIPSIS
    {...
     'current-jobs-ready': 0,
     'current-jobs-reserved': 0,
     'current-jobs-urgent': 0,
     ...
     'name': 'default',
     ...}

> Finally, there's an abundant amount of server-level statistics accessible via
the `Connection`'s `stats` method. We won't go into details here, but:

最后，通过调用`Connection`的`stats`方法，可以获取大量的server-level的统计数据。我们在这里就不细说了，但是：

    >>> pprint(beanstalk.stats())                   # doctest: +ELLIPSIS
    {...
     'current-connections': 1,
     'current-jobs-buried': 0,
     'current-jobs-delayed': 0,
     'current-jobs-ready': 0,
     'current-jobs-reserved': 0,
     'current-jobs-urgent': 0,
     ...}


> Advanced Operation

高级操作
------------------

> In "Basic Operation" above, we discussed the typical lifecycle of a job:

在上文的"基础操作"中，我们讨论了job的典型的生命周期：

     put            reserve               delete
    -----> [READY] ---------> [RESERVED] --------> *poof*


    (This picture was taken from beanstalkd's protocol documentation. It is
    originally contained in `protocol.txt`, part of the beanstalkd
    distribution.) #doctest:+SKIP
    (这个图片是从beanstalkd协议文档中拿的，它本来包含在`protocal.txt`中)

> But besides `ready` and `reserved`, a job can also be `delayed` or `buried`.
Along with those states come a few transitions, so the full picture looks like
the following:

除了`ready`和`reserved`之外，一个job也可以会是`delayed`或者`buried`状态。有一些过度伴随着这些状态，下面的是完整的图片：

       put with delay               release with delay
      ----------------> [DELAYED] <------------.
                            |                   |
                            | (time passes)     |
                            |                   |
       put                  v     reserve       |       delete
      -----------------> [READY] ---------> [RESERVED] --------> *poof*
                           ^  ^                |  |
                           |   \  release      |  |
                           |    `-------------'   |
                           |                      |
                           | kick                 |
                           |                      |
                           |       bury           |
                        [BURIED] <---------------'
                           |
                           |  delete
                            `--------> *poof*


      (This picture was taken from beanstalkd's protocol documentation. It is
      originally contained in `protocol.txt`, part of the beanstalkd
      distribution.) #doctest:+SKIP

> Now let's have a practical look at those new possibilities. For a start, we can
create a job with a delay. Such a job will only be available for reservation
once this delay passes:

现在，来看看这些新的可能性。首先，我们创建一个带有dalay的job, 这样的job只有在通过延迟的时候才可获得：

    >>> beanstalk.put('yes!', delay=1)
    4

    >>> beanstalk.reserve(timeout=0) is None
    True

    >>> job = beanstalk.reserve(timeout=1)
    >>> job.body
    'yes!'

> If we are not interested in a job anymore (e.g. after we failed to
process it), we can simply release the job back to the tube it came from:

如果我们对job不感兴趣（比如，处理失败），我们可以简单的释放这个job回 它来的那个tube:

    >>> job.release()
    >>> job.stats()['state']
    'ready'

> Want to get rid of a job? Well, just "bury" it! A buried job is put aside and is
therefore not available for reservation anymore:

想要除去一个job? 只需"bury"它！一个buried job被放在旁边，并且因此不会为了预留而获得：

    >>> job = beanstalk.reserve()
    >>> job.bury()
    >>> job.stats()['state']
    'buried'

    >>> beanstalk.reserve(timeout=0) is None
    True

> Buried jobs are maintained in a special FIFO-queue outside of the normal job
processing lifecycle until they are kicked alive again:

Buried jobs被维护在 正常job处理生命周期的外部 一个特别的 FIFO-queue中，直到他们被再次kicked alive：

    >>> beanstalk.kick()
    1

> You can request many jobs to be kicked alive at once, `kick`'s return value will
tell you how many jobs were actually kicked alive again:

你可以同时请求很多jobs来kicked alive，`kick`返回的值将告诉你有多少jobs被实际kicked alive：

    >>> beanstalk.kick(42)
    0

> If you still have a handle to a job (or know its job ID), you can also kick
alive this particular job, overriding the FIFO operation of the burial queue:

如果你仍持有一个job的句柄(或者知道它的job ID), 你也可以kick alive这个特别的job, 覆盖burial queue的FIFO操作：

    >>> job = beanstalk.reserve()
    >>> job.bury()
    >>> job.stats()['state']
    'buried'
    >>> job.kick()
    >>> job.stats()['state']
    'ready'

(NOTE: The `kick-job` command was introduced in beanstalkd v1.8.)
(NOTE: `kick-job`命令在beanstalkd v1.8中被介绍)

Inspecting Jobs

检查jobs
---------------

> Besides reserving jobs, a client can also "peek" at jobs. This allows to inspect
jobs without modifying their state. If you know the `id` of a job you're
interested, you can directly peek at the job. We still have job #4 hanging
around from our previous examples, so:

除了 reserving jobs, 一个client也可以 "peek" at jobs。这允许不更改他们状态来检查jobs，如果你知道你感兴趣的job的`id`, 你可以直接peek at the job。我们仍然持有上个例子中＃4 job的句柄，因此：

    >>> job = beanstalk.peek(4)
    >>> job.body
    'yes!'

> Note that this peek did *not* reserve the job:

注意那是peek，不是reserve job

    >>> job.stats()['state']
    'ready'

> If you try to peek at a non-existing job, you'll simply see nothing:

如果你尝试peek at 一个不存在job，你将不会看到任何东西：

    >>> beanstalk.peek(42) is None
    True

> If you are not interested in a particular job, but want to see jobs according to
their state, beanstalkd also provides a few commands. To peek at the same job
that would be returned by `reserve` -- the next ready job -- use `peek-ready`:

如果你一个特别的job不感兴趣，但是想根据他们的状态看看jobs, beanstalkd也提供了一些命令。来peek at相同的job, 将会通过reserve返回，-- 下一个ready job -- 使用peek-ready:

    >>> job = beanstalk.peek_ready()
    >>> job.body
    'yes!'

> Note that you can't release, or bury a job that was not reserved by you. Those
requests on unreserved jobs are silently ignored:

注意你不能release或者bury一个job，因为它不是通过你reserved的。那些在unreserved jobs上的请求会被默默的忽略掉：

    >>> job.release()
    >>> job.bury()

    >>> job.stats()['state']
    'ready'

> You can, though, delete a job that was not reserved by you:

但是，你可以删除一个 不是通过你 reserved的job：

    >>> job.delete()
    >>> job.stats()                         # doctest: +IGNORE_EXCEPTION_DETAIL
    Traceback (most recent call last):
    CommandFailed: ('stats-job', 'NOT_FOUND', [])

> Finally, you can also peek into the special queues for jobs that are delayed:

最后，你也可以peek into 特殊的delayed队列:

    >>> _ = beanstalk.put('o tempores', delay=120)
    >>> job = beanstalk.peek_delayed()
    >>> job.stats()['state']
    'delayed'

... or buried:
... 或者 buried:

    >>> _ = beanstalk.put('o mores!')
    >>> job = beanstalk.reserve()
    >>> job.bury()

    >>> job = beanstalk.peek_buried()
    >>> job.stats()['state']
    'buried'


> Job Priorities

job优先级
--------------

> Without job priorities, beanstalkd operates as a FIFO queue:

没有job优先级的话，beanstalkd操作是一个FIFO队列

    >>> _ = beanstalk.put('1')
    >>> _ = beanstalk.put('2')

    >>> job = beanstalk.reserve() ; print(job.body) ; job.delete()
    1
    >>> job = beanstalk.reserve() ; print(job.body) ; job.delete()
    2

> If need arises, you can override this behaviour by giving different jobs
different priorities. There are three hard facts to know about job priorities:

如果需要，你可以覆盖这种行为通过给不同的job不同的优先级。有三个关于job优先级的事实需要知道：

  1. Jobs with lower priority numbers are reserved before jobs with higher
  priority numbers.

  2. beanstalkd priorities are 32-bit unsigned integers (they range from 0 to
  2**32 - 1).

  3. beanstalkc uses 2**31 as default job priority
  (`beanstalkc.DEFAULT_PRIORITY`).
  
  1. 低优先数字的job 被reserved在 高优先数字的job 之前。
  2. beanstalkd优先急是 32位 无符号整形（0-2*＊32－1）。
  3. beanstalkc 使用 2*＊31作为默认的job优先级 (`beanstalkc.DEFAULT_PRIORITY`)。

> To create a job with a custom priority, use the keyword-argument `priority`:

使用定制的优先级来创建一个job，使用keyword-argument `priority`:

    >>> _ = beanstalk.put('foo', priority=42)
    >>> _ = beanstalk.put('bar', priority=21)
    >>> _ = beanstalk.put('qux', priority=21)

    >>> job = beanstalk.reserve() ; print(job.body) ; job.delete()
    bar
    >>> job = beanstalk.reserve() ; print(job.body) ; job.delete()
    qux
    >>> job = beanstalk.reserve() ; print(job.body) ; job.delete()
    foo

> Note how `'bar'` and `'qux'` left the queue before `'foo'`, even though they
were enqueued well after `'foo'`. Note also that within the same priority jobs
are still handled in a FIFO manner.

注意 `'bar'`和`'qux'`在`'foo'`前出队，尽管他们在`'foo'`后入队。注意，相同优先级的job仍然是按照FIFO的处理方式。


> Fin!

结！
----

    >>> beanstalk.close()

> That's it, for now. We've left a few capabilities untouched (touch and
time-to-run). But if you've really read through all of the above, send me a
message and tell me what you think of it. And then go get yourself a treat. You
certainly deserve it.

目前来说，就这样吧。我们留下一些未提到的功能(touch and time-to-run)。但是如果你确实将上面的读完了，给我发送信息吧...


> Appendix A: beanstalkc and YAML

附录A: beanstalkc 和 YAML
-------------------------------

> As beanstalkd uses YAML for diagnostic information (like the results of
`stats()` or `tubes()`), you'll typically need [PyYAML](). Depending on your
performance needs, you may want to supplement that with the [libyaml]() C
extension.

beanstalkd使用YAML为了诊断信息（像是`stats()`或者`tubes()`的结果），为此你需要PyYAML。取决于你的性能需求，你也许想使用libyaml C扩展来补充它。

[PyYAML]: http://pyyaml.org/
[libyaml]: http://pyyaml.org/wiki/LibYAML

> If, for whatever reason, you cannot use PyYAML, you can still use beanstalkc
and just leave the YAML responses unparsed. To do that, pass `parse_yaml=False`
when creating the `Connection`:

如果因为何种理由，你不能使用PyYAML，你仍可以使用beanstalkc，仅仅是没了YAML来解析返回值。当创建 `Connection`时加上`parse_yaml=False`就可以了：

    >>> beanstalk = beanstalkc.Connection(host='localhost',
    ...                                   port=14711,
    ...                                   parse_yaml=False)

    >>> beanstalk.tubes()
    '---\n- default\n'

    >>> beanstalk.stats_tube('default')             # doctest: +ELLIPSIS
    '---\nname: default\ncurrent-jobs-urgent: 0\ncurrent-jobs-ready: 0\n...'

    >>> beanstalk.close()

> This possibility is mostly useful if you don't use the introspective
capabilities of beanstalkd (`Connection#tubes`, `Connection#watching`,
`Connection#stats`, `Connection#stats_tube`, and `Job#stats`).

这个可能是最有用的，如果你不使用beanstalkd自带的能力(`Connection#tubes`, `Connection#watching`, `Connection#stats`, `Connection#stats_tube`, and `Job#stats`)

> Alternatively, you can also pass a function to be used as YAML parser:

可选的，你也可以用一个函数来解析，就像是YAML解析一样：

    >>> beanstalk = beanstalkc.Connection(host='localhost',
    ...                                   port=14711,
    ...                                   parse_yaml=lambda x: x.split('\n'))

    >>> beanstalk.tubes()
    ['---', '- default', '']

    >>> beanstalk.stats_tube('default')             # doctest: +ELLIPSIS
    ['---', 'name: default', 'current-jobs-urgent: 0', ...]

    >>> beanstalk.close()

> This should come in handy if PyYAML simply does not fit your needs.

这应该是很方便的，如果PyYAML不适应你的需求。
